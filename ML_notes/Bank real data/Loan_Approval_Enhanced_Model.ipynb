{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da8c65e",
   "metadata": {},
   "source": [
    "# ðŸ“š Loan Approval Prediction - Real-World Enhanced Model\n",
    "This notebook includes complete data preprocessing and model optimization for:\n",
    "- **Loan Approval Prediction Dataset**\n",
    "âœ… Feature selection using P-values and VIF\n",
    "âœ… Handling outliers using Z-score/IQR\n",
    "âœ… Ridge and Lasso Regularization to prevent overfitting\n",
    "âœ… Residual analysis for model assumptions\n",
    "âœ… Handling missing data\n",
    "âœ… Scaling and transforming features\n",
    "âœ… Proper handling of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8280f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40beb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loan Approval Dataset\n",
    "data_loan = {\n",
    "    'LoanAmount': [150, 120, 180, 130, 140, 200, 160, 110, 170, 190],\n",
    "    'ApplicantIncome': [4000, 3500, 6000, 3000, 4500, 7500, 4200, 3200, 5800, 6200],\n",
    "    'CoapplicantIncome': [0, 1500, 1800, 0, 1200, 2000, 0, 800, 1500, 0],\n",
    "    'LoanTerm': [360, 180, 360, 240, 360, 180, 300, 360, 360, 180],\n",
    "    'CreditHistory': [1, 0, 1, 1, 1, 0, 1, 1, 0, 1],\n",
    "    'PropertyArea': ['Urban', 'Rural', 'Urban', 'Semiurban', 'Urban', 'Rural', 'Semiurban', 'Urban', 'Rural', 'Urban'],\n",
    "    'LoanStatus': [1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_loan = pd.DataFrame(data_loan)\n",
    "\n",
    "# --- Check for Missing Values ---\n",
    "print(\"Loan Data Missing Values:\")\n",
    "print(df_loan.isnull().sum())\n",
    "\n",
    "# --- Outlier Detection & Removal ---\n",
    "z_scores_loan = np.abs(stats.zscore(df_loan.select_dtypes(include=[np.number])))\n",
    "df_loan_clean = df_loan[(z_scores_loan < 3).all(axis=1)]\n",
    "\n",
    "# --- One-Hot Encoding for Categorical Variables ---\n",
    "df_loan_encoded = pd.get_dummies(df_loan_clean, columns=['PropertyArea'], drop_first=True)\n",
    "\n",
    "# --- Feature Selection ---\n",
    "X_loan = df_loan_encoded.drop(columns=['LoanStatus'])\n",
    "y_loan = df_loan_encoded['LoanStatus']\n",
    "\n",
    "# Add constant for intercept\n",
    "X_loan_const = sm.add_constant(X_loan)\n",
    "model_sm_loan = sm.OLS(y_loan, X_loan_const).fit()\n",
    "print(model_sm_loan.summary())\n",
    "\n",
    "# Drop insignificant features if P-value > 0.05\n",
    "X_loan_selected = X_loan_const.drop(columns=['CoapplicantIncome'], errors='ignore')\n",
    "\n",
    "# --- VIF Check ---\n",
    "vif_data_loan = pd.DataFrame()\n",
    "vif_data_loan[\"Feature\"] = X_loan_selected.columns\n",
    "vif_data_loan[\"VIF\"] = [variance_inflation_factor(X_loan_selected.values, i) for i in range(X_loan_selected.shape[1])]\n",
    "print(\"\n",
    "Loan Data VIF:\n",
    "\", vif_data_loan)\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "scaler_loan = StandardScaler()\n",
    "X_loan_scaled = scaler_loan.fit_transform(X_loan_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11489fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train-Test Split ---\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_loan_scaled, y_loan, test_size=0.2, random_state=0)\n",
    "\n",
    "# --- Logistic Regression, Ridge, and Lasso for Loan Status ---\n",
    "logistic_loan = LogisticRegression(max_iter=1000)\n",
    "ridge_loan = RidgeClassifier(alpha=1.0)\n",
    "lasso_loan = LassoCV(cv=5, max_iter=1000)\n",
    "\n",
    "# Fit models\n",
    "logistic_loan.fit(X_train_l, y_train_l)\n",
    "ridge_loan.fit(X_train_l, y_train_l)\n",
    "\n",
    "# Predictions\n",
    "y_pred_logistic_l = logistic_loan.predict(X_test_l)\n",
    "y_pred_ridge_l = ridge_loan.predict(X_test_l)\n",
    "\n",
    "# --- Evaluation for Loan Models ---\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_l, y_pred_logistic_l))\n",
    "print(\"Ridge Classifier Accuracy:\", accuracy_score(y_test_l, y_pred_ridge_l))\n",
    "print(\"\n",
    "Classification Report (Logistic):\n",
    "\", classification_report(y_test_l, y_pred_logistic_l))\n",
    "print(\"\n",
    "Confusion Matrix (Logistic):\n",
    "\", confusion_matrix(y_test_l, y_pred_logistic_l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6be0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Residual Analysis for Loan Data ---\n",
    "residuals_l = y_test_l - y_pred_logistic_l\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals_l, kde=True, bins=10)\n",
    "plt.title('Residuals for Loan Prediction Model')\n",
    "plt.xlabel('Residuals')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
